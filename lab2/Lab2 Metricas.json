{"paragraphs":[{"text":"import java.sql.Timestamp\r\nimport org.apache.spark.sql.Dataset\r\nimport org.apache.spark.sql.DataFrame\r\nimport scala.util.{Try, Success, Failure}\r\nimport org.apache.spark.sql.expressions.Window\r\nimport org.apache.spark.sql.functions._\r\nimport org.apache.spark.sql.SparkSession\r\n\r\nval spark: SparkSession = SparkSession.builder().getOrCreate()\r\n\r\nval hits = spark.read.load(\"<PATH TO PARQUET>/hits.parquet\")\r\nval sessions = spark.read.load(\"<PATH TO PARQUET>/result.parquet\")\r\n\r\n","dateUpdated":"2016-11-02T22:42:16-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837797_1439659954","id":"20161028-185704_1769943653","result":{"code":"SUCCESS","type":"TEXT","msg":"\nimport org.apache.spark.sql.functions.udf\n\nimport java.sql.Timestamp\n\nimport org.apache.spark.sql.Dataset\n\nimport org.apache.spark.sql.DataFrame\n\nimport scala.util.{Try, Success, Failure}\n\nimport org.apache.spark.sql.expressions.Window\n\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.sql.SparkSession\n\nspark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6e2f3ebc\n\nhits: org.apache.spark.sql.DataFrame = [timeStamp: timestamp, user_id: string ... 2 more fields]\n\nsessions: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 6 more fields]\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:341"},{"title":"Cantidad de usuarios distintos por día.","text":"val query1 = hits.groupBy(dayofyear(hits(\"timeStamp\")).as(\"day\"))\n                  .agg(countDistinct(hits(\"user_id\")).as(\"amount Users\"))\n                  \nquery1.show(false)","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837798_1440814201","id":"20161102-131555_1768650763","result":{"code":"SUCCESS","type":"TEXT","msg":"\nquery1: org.apache.spark.sql.DataFrame = [day: int, amount Users: bigint]\n+---+------------+\n|day|amount Users|\n+---+------------+\n|217|1           |\n|216|652827      |\n|215|641974      |\n+---+------------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:342"},{"title":"Cantidad de usuarios que retornan por día.","text":"val query2 = sessions.groupBy(dayofmonth(sessions(\"beginSession\")).as(\"Day\"),month(sessions(\"beginSession\")).as(\"Month\"), year(sessions(\"beginSession\")).as(\"Year\"), $\"user_id\")\n                     .agg(when((max(\"session\")) - min(\"session\") >= 1, 1).otherwise(0).as(\"return\")).sort(asc(\"day\"))\n                     \nval res = query2.groupBy(query2(\"Day\"), query2(\"Month\"), query2(\"Year\")).agg(count(\"return\").as(\"users who returned\"))\nres.show(false)","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837798_1440814201","id":"20161102-131624_1474662931","result":{"code":"SUCCESS","type":"TEXT","msg":"\nquery2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Day: int, Month: int ... 3 more fields]\n\nres: org.apache.spark.sql.DataFrame = [Day: int, Month: int ... 2 more fields]\n+---+-----+----+------------------+\n|Day|Month|Year|users who returned|\n+---+-----+----+------------------+\n|2  |8    |2016|641974            |\n|3  |8    |2016|650795            |\n|4  |8    |2016|1                 |\n+---+-----+----+------------------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:343"},{"title":"Duración promedio de una sesión.","text":"val diff_ms_col = sessions(\"EndSession\").cast(\"long\") - col(\"BeginSession\").cast(\"long\")\nval query3 = sessions.withColumn(\"dif_ms\", diff_ms_col)\nval res = query3.agg(avg(\"dif_ms\").as(\"Media in Ms\"))\nres.show(false)","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837798_1440814201","id":"20161102-131632_1383568021","result":{"code":"SUCCESS","type":"TEXT","msg":"\ndiff_ms_col: org.apache.spark.sql.Column = (CAST(EndSession AS BIGINT) - CAST(BeginSession AS BIGINT))\n\nquery3: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 7 more fields]\n\nres: org.apache.spark.sql.DataFrame = [Media in Ms: double]\n+-----------------+\n|Media in Ms      |\n+-----------------+\n|259.8718308568991|\n+-----------------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:344"},{"title":"Mediana de renders, plays y checkout por sesión.","text":"//Mean Checkout\r\n\r\nval query4 = sessions\r\nval dfRowCount : Double = query4.count\r\n\r\nval checkout_ord = Window.orderBy(\"Checkout\")\r\nval row_numberDF = row_number().over(checkout_ord)\r\nval checkout_numbered  = query4.select('*, row_numberDF as 'n_row)\r\n\r\nval mean_checkout = checkout_numbered.filter($\"n_row\" >= (scala.math.floor((dfRowCount+1.0)/2.0)).toInt && $\"n_row\" <= (scala.math.ceil((dfRowCount+1.0)/2.0)).toInt).toDF.groupBy().avg(\"Checkout\")\r\n\r\n//Mean Play\r\nval play_ord = Window.orderBy(\"Play\")\r\nval row_numberDFP = row_number().over(play_ord)\r\nval play_ordered = query4.select('*, row_numberDFP as 'n_row)\r\n\r\nval mean_play = play_ordered.filter($\"n_row\" >= (scala.math.floor((dfRowCount+1.0)/2.0)).toInt && $\"n_row\" <= (scala.math.ceil((dfRowCount+1.0)/2.0)).toInt).toDF.groupBy().avg(\"Play\")\r\n\r\n//Mean Render\r\nval render_ord = Window.orderBy(\"Render\")\r\nval row_numberDFR = row_number().over(render_ord)\r\nval render_ordered = query4.select('*, row_numberDFR as 'n_row)\r\n\r\nval mean_render = render_ordered.filter($\"n_row\" >= (scala.math.floor((dfRowCount+1.0)/2.0)).toInt && $\"n_row\" <= (scala.math.ceil((dfRowCount+1.0)/2.0)).toInt).toDF.groupBy().avg(\"Render\")\r\n\r\nval tmp = mean_checkout.join(mean_play)\r\nval res = tmp.join(mean_render)\r\n\r\nres.show(false)\r\n","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837799_1440429452","id":"20161102-131709_1978324903","result":{"code":"SUCCESS","type":"TEXT","msg":"\nquery4: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 6 more fields]\n\ndfRowCount: Double = 1462856.0\n\ncheckout_ord: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@308e1e0e\n\nrow_numberDF: org.apache.spark.sql.Column = ROW_NUMBER() OVER ( ORDER BY Checkout ASC UnspecifiedFrame)\n\ncheckout_numbered: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 7 more fields]\n\nmean_checkout: org.apache.spark.sql.DataFrame = [avg(Checkout): double]\n\nplay_ord: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@415e1178\n\nrow_numberDFP: org.apache.spark.sql.Column = ROW_NUMBER() OVER ( ORDER BY Play ASC UnspecifiedFrame)\n\nplay_ordered: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 7 more fields]\n\nmean_play: org.apache.spark.sql.DataFrame = [avg(Play): double]\n\nrender_ord: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@1bcbb8a6\n\nrow_numberDFR: org.apache.spark.sql.Column = ROW_NUMBER() OVER ( ORDER BY Render ASC UnspecifiedFrame)\n\nrender_ordered: org.apache.spark.sql.DataFrame = [user_id: string, session: int ... 7 more fields]\n\nmean_render: org.apache.spark.sql.DataFrame = [avg(Render): double]\n\ntmp: org.apache.spark.sql.DataFrame = [avg(Checkout): double, avg(Play): double]\n\nres: org.apache.spark.sql.DataFrame = [avg(Checkout): double, avg(Play): double ... 1 more field]\n+-------------+---------+-----------+\n|avg(Checkout)|avg(Play)|avg(Render)|\n+-------------+---------+-----------+\n|0.0          |0.0      |1.0        |\n+-------------+---------+-----------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:345"},{"title":"Cantidad de visitas por hora.","text":"val query5 = hits.groupBy(hour(hits(\"timeStamp\")).as(\"Hour\"), dayofmonth(hits(\"timeStamp\")).as(\"Day\"),month(hits(\"timeStamp\")).as(\"Month\"), year(hits(\"timeStamp\")).as(\"Year\"))\n                    .agg(countDistinct(hits(\"user_id\")).as(\"amount Users\")).sort(asc(\"Day\"),asc(\"Hour\"))\nquery5.show(50,false)","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837799_1440429452","id":"20161102-131635_155320381","result":{"code":"SUCCESS","type":"TEXT","msg":"\nquery5: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Hour: int, Day: int ... 3 more fields]\n+----+---+-----+----+------------+\n|Hour|Day|Month|Year|amount Users|\n+----+---+-----+----+------------+\n|0   |2  |8    |2016|48247       |\n|1   |2  |8    |2016|53318       |\n|2   |2  |8    |2016|51938       |\n|3   |2  |8    |2016|43705       |\n|4   |2  |8    |2016|32388       |\n|5   |2  |8    |2016|23648       |\n|6   |2  |8    |2016|15341       |\n|7   |2  |8    |2016|9969        |\n|8   |2  |8    |2016|7302        |\n|9   |2  |8    |2016|7271        |\n|10  |2  |8    |2016|10415       |\n|11  |2  |8    |2016|16408       |\n|12  |2  |8    |2016|25995       |\n|13  |2  |8    |2016|35273       |\n|14  |2  |8    |2016|39733       |\n|15  |2  |8    |2016|39499       |\n|16  |2  |8    |2016|39162       |\n|17  |2  |8    |2016|39152       |\n|18  |2  |8    |2016|39527       |\n|19  |2  |8    |2016|39043       |\n|20  |2  |8    |2016|39802       |\n|21  |2  |8    |2016|38033       |\n|22  |2  |8    |2016|37495       |\n|23  |2  |8    |2016|40203       |\n|0   |3  |8    |2016|45487       |\n|1   |3  |8    |2016|50445       |\n|2   |3  |8    |2016|49904       |\n|3   |3  |8    |2016|42193       |\n|4   |3  |8    |2016|32128       |\n|5   |3  |8    |2016|22965       |\n|6   |3  |8    |2016|15188       |\n|7   |3  |8    |2016|10089       |\n|8   |3  |8    |2016|7532        |\n|9   |3  |8    |2016|7394        |\n|10  |3  |8    |2016|10588       |\n|11  |3  |8    |2016|17290       |\n|12  |3  |8    |2016|30924       |\n|13  |3  |8    |2016|36432       |\n|14  |3  |8    |2016|39356       |\n|15  |3  |8    |2016|40005       |\n|16  |3  |8    |2016|40465       |\n|17  |3  |8    |2016|39569       |\n|18  |3  |8    |2016|39878       |\n|19  |3  |8    |2016|39697       |\n|20  |3  |8    |2016|40229       |\n|21  |3  |8    |2016|40273       |\n|22  |3  |8    |2016|40570       |\n|23  |3  |8    |2016|41034       |\n|22  |4  |8    |2016|1           |\n+----+---+-----+----+------------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:346"},{"title":"Valor promedio por checkout por sesion.","text":"val query6 = sessions.agg(avg(sessions(\"Checkout\")).as(\"avg Checkout\"))\nquery6.show(false)","dateUpdated":"2016-11-02T22:33:57-0300","config":{"editorMode":"ace/mode/scala","colWidth":12,"title":true,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}}},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837800_1438505707","id":"20161028-185943_1739894816","result":{"code":"SUCCESS","type":"TEXT","msg":"\nquery6: org.apache.spark.sql.DataFrame = [avg Checkout: double]\n+------------------+\n|avg Checkout      |\n+------------------+\n|0.4481233969714039|\n+------------------+\n\n"},"dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:347"},{"text":"","dateUpdated":"2016-11-02T22:33:57-0300","config":{"colWidth":12,"enabled":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1478136837800_1438505707","id":"20161102-131338_1248273164","dateCreated":"2016-11-02T22:33:57-0300","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:348"}],"name":"Lab2 Metricas","id":"2C1JAVTYZ","angularObjects":{"2BYG18AFT:shared_process":[],"2BYN9HQZ6:shared_process":[],"2BVHAU8UT:shared_process":[],"2BYTB1E3C:shared_process":[],"2BY3E4HG4:shared_process":[],"2BWYK9YRZ:shared_process":[],"2BYTUGFKV:shared_process":[],"2BWZBUGMQ:shared_process":[],"2BW84U257:shared_process":[],"2BXYDX8TG:shared_process":[],"2BV7ATBB1:shared_process":[],"2BV2XF9GX:shared_process":[],"2BYPH6594:shared_process":[],"2BZ1RHW65:shared_process":[],"2BX4WB4VE:shared_process":[],"2BWQ1292A:shared_process":[],"2BVCM8FP1:shared_process":[],"2BXAMPJ7J:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}